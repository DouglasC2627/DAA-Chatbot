version: '3.8'

services:
  # Backend API Service
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: daa-chatbot-backend
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_HOST=http://host.docker.internal:11434
      - OLLAMA_MODEL=llama3.2
      - EMBEDDING_MODEL=nomic-embed-text
      - DATABASE_URL=sqlite:///./storage/sqlite/app.db
      - CHROMA_PERSIST_DIR=./storage/chroma
      - UPLOAD_DIR=./storage/documents
      - MAX_FILE_SIZE=10485760
    volumes:
      - ./backend:/app
      - backend-storage:/app/storage
    networks:
      - daa-network
    restart: unless-stopped
    # Note: Ollama must be running on the host machine
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Frontend Next.js Service
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: daa-chatbot-frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NEXT_PUBLIC_WS_URL=ws://localhost:8000
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    networks:
      - daa-network
    depends_on:
      - backend
    restart: unless-stopped

networks:
  daa-network:
    driver: bridge

volumes:
  backend-storage:
    driver: local
